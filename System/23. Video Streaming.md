## Intro

Media content today is increasingly streamed video, and this trend will only grow as the speed of **consumer internet**
and **video quality**improve.

The video delivery market is segmented into two parts: **live** and **on-demand** video streaming. On-demand video is
video content that has been produced and transcoded in its **entirety** **prior to delivery**, and it may be watched or
rewatched at any point in time. Movies and television programs are good examples of on-demand video streams. Live video
streaming comes direct from a source, transcoded and delivered to consumers **in real time**. A good example of live
video streaming is a sporting event.

<img width="624" alt="image" src="https://user-images.githubusercontent.com/47337188/169624078-7c970e17-28b0-40de-a00f-c8a40f81d0dd.png">

### Encoding

The segments, or chunks, of the video are created by an encoding process. Video encoding is the process of **slicing**
and **compressing** raw video into **segments** via a codec that can be decoded by players. Encoders can produce **multiple versions** of each segment at differing **bitrates**. The encoder also produces a **manifest file** that
provides metadata about the video, supported bitrates, encodings, and where to find segments.

### Playback

Streaming video **clients** will first download a **manifest** file that describes video metadata, including data about
segments available for download. For **on-demand** video, the manifest contains data about **all segments**; for **live** video, the **manifest** is regularly **updated** by the live encoder and downloaded by the player.

A video streaming **player** will typically require **three segments** before allowing playback of the video. After
playback starts, the player will continue to **buffer ahead** to ensure that playback is not interrupted by waiting for
a segment download. Players will allow the user to select a specific quality setting or use an **adaptive bitrate (ABR)
algorithm**, which will automatically select the best bitrate that is capable of being buffered ahead for smooth
streaming, given the client’s bandwidth and latency from the server.

### Delivery

To provide end users with the best streaming experience, video is typically delivered through a **CDN**.

A content delivery network, or content distribution network (CDN), is a geographically distributed network of proxy **servers** and their **data centers**.

CDNs provide many locations that act as content **caches**. The locations (called points of presence, or PoPs) are **distributed** around the globe to be close to end users, to keep latency down. The PoPs cache recently requested
content; they also fetch content that is not cached locally and store it for a specified period.

Client players are directed to retrieve video from a CDN.

The **client** request uses geographic or latency-based **DNS routing** to direct the client to the **nearest PoP**. The
server to which the request is directed will either have the content cached or not. Depending on how the CDN operates,
the request may be **directed to other** servers. Once the content is located, it will be **cached** by servers **along
the request’s path** to improve performance the next time the asset is requested. Finally, the content is delivered to
the client.

### Protocols

Currently, the emerging video streaming **protocols**, Apple HTTP Live Streaming (HLS) and MPEG-Dynamic Adaptive
Streaming over HTTP (MPEG-DASH), follow a similar delivery premise: small segments of the video are downloaded via **
HTTP(S)**. The use of HTTP(S) enables us to take advantage of **HTTP/2** and **content delivery networks** for
optimization.

## Design Youtube or Netflix

Contents below are
from [https://www.educative.io/courses/grokking-the-system-design-interview/xV26VjZ7yMl](https://www.educative.io/courses/grokking-the-system-design-interview/xV26VjZ7yMl)
.


<table>
  <tr>
   <td>Requirements</td>
   <td>
Functional:
<ul>
<li>upload video
<li>share and view video
<li>search by video title
<li>record video stat: (dis)likes, views
<li>add and view comments
</ul>
Non-functional:
<ul>
<li>Reliable: no lost
<li>Available: over consistency
<li>Real-time
</ul>
   </td>
  </tr>
  <tr>
   <td>Capacity Estimation
   </td>
   <td>…
   </td>
  </tr>
  <tr>
   <td>System APIs
   </td>
   <td>uploadVideo(<strong>api_dev_key</strong>, <strong>video_title</strong>, video_description, tags[], category_id, default_language, recording_details, <strong>video_contents</strong>): String 

searchVideo(<strong>api_dev_key</strong>, <strong>search_query</strong>, user_location, <strong>
maximum_videos_to_return</strong>, page_token): JSON

streamVideo(<strong>api_dev_key</strong>, <strong>video_id</strong>, <strong>offset</strong>, <strong>codec</strong>
, <strong>resolution</strong>): Stream

*We should send the codec and resolution info in the API from the client to support play/pause from multiple devices.
Imagine you are watching a video on your TV’s Netflix app, paused it, and started watching it on your phone’s Netflix
app. In this case, you would need codec and resolution, as both these devices have a different resolution and use a
different codec.
   </td>
  </tr>
  <tr>
   <td>High Level Design
   </td>
   <td>Components:
<ul>

<li>Processing Queue

<li>Encoder

<li>Thumbnails generator

<li>Video and Thumbnail storage

<li>User database

<li>Video metadata storage
</li>
</ul>
   </td>
  </tr>
  <tr>
   <td>Database Schema
   </td>
   <td>…
   </td>
  </tr>
  <tr>
   <td>Detailed Component Design
   </td>
   <td>Videos can be stored in a distributed file storage system like HDFS.
<p>
Heavy read:
<ul>

<li>separate read traffic from write traffic; 

<li>video copies on different servers to distribute read traffic; 

<li>for metadata, primary-secondary cluster;

</ul>
Thumbnails are small &lt;= 5KB, heavier read. They can be stored in Bigtable, cache added.
<p>
Supports resuming uploading when connection losts.
<p>
Video encoding: Newly uploaded videos are stored on the server, and a new task is added to the processing queue to encode the video into multiple formats. Once all the encoding is completed, the uploader will be notified, and the video is made available for view/sharing.
   </td>
  </tr>
</table>

## *References

[https://learning.oreilly.com/library/view/optimize-video-streaming/9781098111649/](https://learning.oreilly.com/library/view/optimize-video-streaming/9781098111649/)

[https://en.wikipedia.org/wiki/Content_delivery_network](https://en.wikipedia.org/wiki/Content_delivery_network)

[https://bitmovin.com/what-is-transcoding/](https://bitmovin.com/what-is-transcoding/)

[https://www.educative.io/courses/grokking-the-system-design-interview/xV26VjZ7yMl](https://www.educative.io/courses/grokking-the-system-design-interview/xV26VjZ7yMl)
